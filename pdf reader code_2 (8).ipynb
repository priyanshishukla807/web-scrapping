{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "# Sample dataframe with text column\n",
    "data = {'text_column': [\n",
    "    'India is followed by the Democratic Republic of Congo on 178th rank, Bangladesh on 179th and Burundi on 180th.',\n",
    "    'Top five nations with the best EPI index are Switzerland, France, Denmark, Malta and Sweden respectively.',\n",
    "    'Long and Short Paragraphs on Pollution in English',\n",
    "    'Environmental pollution refers to the presence of harmful and poisonous substances into our environment...',\n",
    "    'Mobile application development is the process of making software for smartphones, tablets and digital assistants...'\n",
    "]}\n",
    "text_df = pd.DataFrame(data)\n",
    "\n",
    "# Sample extracted text\n",
    "extracted_text = \"\"\"\n",
    "India is followed by the Democratic Republic of Congo on 178th rank, Bangladesh on 179th and Burundi on 180th. \n",
    "Top five nations with the best EPI index are Switzerland, France, Denmark, Malta and Sweden respectively\n",
    "\n",
    "Long and Short Paragraphs on Pollution in English\n",
    "Below we have provided both long and short paragraphs on pollution of varying word lengths...\n",
    "\n",
    "Environmental pollution refers to the presence of harmful and poisonous substances into our environment...\n",
    "Mobile application development is the process of making software for smartphones, tablets and digital assistants...\n",
    "\"\"\"\n",
    "\n",
    "# Split extracted text into paragraphs\n",
    "paragraphs = extracted_text.split('\\n\\n')\n",
    "\n",
    "# Create a DataFrame with paragraphs as rows\n",
    "paragraph_df = pd.DataFrame({'Paragraph': paragraphs})\n",
    "\n",
    "# Create a new DataFrame to store matching results\n",
    "match_results = []\n",
    "\n",
    "# Iterate through each row in the \"text_df\" DataFrame\n",
    "for index, row in text_df.iterrows():\n",
    "    target_text = row['text_column']\n",
    "    \n",
    "    # Match each paragraph with the current row's text\n",
    "    match_scores = paragraph_df['Paragraph'].apply(lambda p: fuzz.token_set_ratio(target_text, p))\n",
    "    \n",
    "    # Find the best matching paragraph\n",
    "    best_match_index = match_scores.idxmax()\n",
    "    best_match_paragraph = paragraph_df.loc[best_match_index, 'Paragraph']\n",
    "    best_match_score = match_scores[best_match_index]\n",
    "    \n",
    "    match_results.append({'Paragraph': best_match_paragraph, 'Match': target_text, 'Match Score': best_match_score})\n",
    "\n",
    "# Create a DataFrame from match_results\n",
    "match_df = pd.DataFrame(match_results)\n",
    "\n",
    "# Print the resulting DataFrame with \"Paragraph\", \"Match\", and \"Match Score\" columns\n",
    "print(match_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save the pdf into dataframe\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Sample extracted text\n",
    "extracted_text = \"\"\"\n",
    "1. Objective\n",
    "1.11 India is followed by the Democratic Republic of Congo on 178th rank, Bangladesh on 179th and Burundi on 180th.\n",
    "Top five nations with the best EPI index are Switzerland, France, Denmark, Malta and Sweden respectively.\n",
    "1.2 Long and Short Paragraphs on Pollution in English\n",
    "Below we have provided both long and short paragraphs on pollution of varying word lengths...\n",
    "1.3 Environmental pollution refers to the presence of harmful and poisonous substances into our environment...\n",
    "2. Application development authority\n",
    "2.1 Mobile application development is the process of making software for smartphones, tablets and digital assistants...\n",
    "2.3 Mobile app development is rapidly growing. From retail, telecommunications and e-commerce to insurance...\n",
    "\"\"\"\n",
    "\n",
    "# Split the extracted text into lines\n",
    "lines = extracted_text.strip().split('\\n')\n",
    "\n",
    "# Regular expression patterns to match titles and descriptions\n",
    "title_pattern = r'^\\d+\\.\\d+\\s+(.*)$'\n",
    "description_pattern = r'^\\d+\\.\\d+\\s+(.*?)\\n\\d+\\.\\d+|\\n*$'\n",
    "\n",
    "# Initialize lists to store titles and descriptions\n",
    "titles = []\n",
    "descriptions = []\n",
    "\n",
    "# Process each line to extract titles and descriptions\n",
    "for line in lines:\n",
    "    title_match = re.match(title_pattern, line)\n",
    "    if title_match:\n",
    "        titles.append(title_match.group(1))\n",
    "    else:\n",
    "        description_match = re.match(description_pattern, line)\n",
    "        if description_match:\n",
    "            descriptions.append(description_match.group(1))\n",
    "\n",
    "# Create a DataFrame from titles and descriptions\n",
    "data = {'Title': titles, 'Description': descriptions}\n",
    "result_df = pd.DataFrame(data)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeaf553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample extracted text\n",
    "extracted_text = \"\"\"\n",
    "India is followed by the Democratic Republic of Congo on 178th rank, Bangladesh on 179th and Burundi on 180th.\n",
    "Top five nations with the best EPI index are Switzerland, France, Denmark, Malta and Sweden respectively.\n",
    "Long and Short Paragraphs on Pollution in English\n",
    "Below we have provided both long and short paragraphs on pollution of varying word lengths...\n",
    "Environmental pollution refers to the presence of harmful and poisonous substances into our environment...\n",
    "Mobile application development is the process of making software for smartphones, tablets and digital assistants...\n",
    "\"\"\"\n",
    "\n",
    "# Split the extracted text into sentences\n",
    "sentences = extracted_text.split('.')\n",
    "\n",
    "# Initialize lists to store titles and descriptions\n",
    "titles = []\n",
    "descriptions = []\n",
    "\n",
    "# Define a threshold for sentence length to distinguish titles from descriptions\n",
    "title_sentence_length = 8  # Adjust as needed\n",
    "\n",
    "# Process each sentence to separate titles and descriptions\n",
    "current_title = \"\"\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.strip()\n",
    "    if len(sentence.split()) <= title_sentence_length:\n",
    "        if current_title:\n",
    "            titles.append(current_title)\n",
    "        current_title = sentence\n",
    "    else:\n",
    "        current_title += \". \" + sentence\n",
    "descriptions.append(current_title)\n",
    "\n",
    "# Create a DataFrame from titles and descriptions\n",
    "data = {'Title': titles, 'Description': descriptions}\n",
    "result_df = pd.DataFrame(data)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013cd9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample extracted text\n",
    "extracted_text = \"\"\"\n",
    "1. Objective\n",
    "1.11 India is followed by the Democratic Republic of Congo on 178th rank, Bangladesh on 179th and Burundi on 180th.\n",
    "Top five nations with the best EPI index are Switzerland, France, Denmark, Malta and Sweden respectively.\n",
    "1.2 Long and Short Paragraphs on Pollution in English\n",
    "Below we have provided both long and short paragraphs on pollution of varying word lengths...\n",
    "1.3 Environmental pollution refers to the presence of harmful and poisonous substances into our environment...\n",
    "2. Application development authority\n",
    "2.1 Mobile application development is the process of making software for smartphones, tablets and digital assistants...\n",
    "2.3 Mobile app development is rapidly growing. From retail, telecommunications and e-commerce to insurance...\n",
    "\"\"\"\n",
    "\n",
    "# Split the extracted text into paragraphs\n",
    "paragraphs = extracted_text.split('\\n')\n",
    "\n",
    "# Initialize lists to store titles and descriptions\n",
    "titles = []\n",
    "descriptions = []\n",
    "current_title = None\n",
    "\n",
    "# Process each paragraph to separate titles and descriptions\n",
    "for paragraph in paragraphs:\n",
    "    if paragraph.strip():\n",
    "        if paragraph.startswith(('1.', '2.', '3.', '4.', '5.')):\n",
    "            if current_title is not None:\n",
    "                titles.append(current_title)\n",
    "            current_title = paragraph.strip()\n",
    "        else:\n",
    "            if current_title is not None:\n",
    "                descriptions.append(paragraph.strip())\n",
    "titles.append(current_title)\n",
    "\n",
    "# Create a DataFrame from titles and descriptions\n",
    "data = {'Title': titles, 'Description': descriptions}\n",
    "result_df = pd.DataFrame(data)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into lines\n",
    "lines = pdf_text.strip().split('\\n')\n",
    "\n",
    "# Initialize variables to store titles and descriptions\n",
    "title = \"\"\n",
    "description = \"\"\n",
    "output = []\n",
    "\n",
    "# Process each line to extract titles and descriptions\n",
    "for line in lines:\n",
    "    if re.match(r'^[A-Za-z\\s]+$', line):\n",
    "        # Save previous title and description if any\n",
    "        if title and description:\n",
    "            output.append({'Title': title, 'Description': description})\n",
    "        title = line.strip()\n",
    "        description = \"\"\n",
    "    else:\n",
    "        description += line + \"\\n\"\n",
    "\n",
    "# Save the last title and description\n",
    "if title and description:\n",
    "    output.append({'Title': title, 'Description': description})\n",
    "\n",
    "# Create a DataFrame from the output\n",
    "df = pd.DataFrame(output)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac879bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Sample text from the PDF\n",
    "pdf_text = \"\"\"\n",
    "Summary\n",
    "A Data Science enthusiast who wants to take up a good professional challenge to solve real \n",
    "world problems using different data science tools like Python, R, MySQL by drawing \n",
    "meaningful insights from real world data. In depth knowledge of statistics. \n",
    "\n",
    "Key skills\n",
    "1. Data & Quantitative Analysis • Data Science • Predictive/Statistical Modelling \n",
    "2. Data Visualization • Machine Learning Algorithms • Data Wrangling \n",
    "\n",
    "Technical skills 2019\n",
    "1. Programming Tools: Python, R, VBA, SQL, SPSS \n",
    "(ii)  Data Visualization Tools: MS Excel, Tableau, Power BI \n",
    "3. Packages: Scikit-Learn, Numpy, Pandas, NLTK, BeautifulSoup, Matplotlib, Seaborn \n",
    "etc. \n",
    "4. Machine Learning: Clustering, Linear/Logistic Regression, SVM, PCA, Ensemble \n",
    "Trees, Random Forests \n",
    "\n",
    "Section 500.01 Definitions \n",
    "CBP -Controls MI & Insights at BARCLAYS ( Jan`23 - Present)\n",
    "Assistant Manager Analytics at PNB MetLife India Insurance Co. Ltd., Gurugram \n",
    "(Aug '21 – Jan`23)\n",
    "\n",
    "Internships\n",
    "(i) Data Analytics Intern at PNB MetLife India Insurance Co. Ltd., Gurugram (Mar \n",
    "'21 - Jul '21) \n",
    "(ii) Data Science Intern at Transabel Technology, Jaipur (Aug '20 - Nov \n",
    "'20)\n",
    "\n",
    "Certification 89\n",
    "1.  Certificate of competency in Fundamentals of Deep Learning for Computer Vision \n",
    "from NVIDIA Deep Learning Institute. \n",
    "2. Python for Data Science and Machine Learning Bootcamp from Udemy. \n",
    "3.  Associate Data Analytics from EXL.\n",
    "\"\"\"\n",
    "\n",
    "# Split the text into lines\n",
    "lines = pdf_text.strip().split('\\n')\n",
    "\n",
    "# Initialize variables to store titles and descriptions\n",
    "output = []\n",
    "title = None\n",
    "description = \"\"\n",
    "\n",
    "# Process each line to extract titles and descriptions\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        continue\n",
    "    \n",
    "    if title is None:\n",
    "        title = line\n",
    "    else:\n",
    "        description += line + \" \"\n",
    "        if line.endswith('.'):\n",
    "            output.append({'Title': title, 'Description': description})\n",
    "            title = None\n",
    "            description = \"\"\n",
    "\n",
    "# Create a DataFrame from the output\n",
    "df = pd.DataFrame(output)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4bb1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Sample text from the PDF\n",
    "pdf_text = \"\"\"\n",
    "Summary\n",
    "A Data Science enthusiast who wants to take up a good professional challenge to solve real \n",
    "world problems using different data science tools like Python, R, MySQL by drawing \n",
    "meaningful insights from real world data. In depth knowledge of statistics. \n",
    "\n",
    "Key skills\n",
    "1. Data & Quantitative Analysis • Data Science • Predictive/Statistical Modelling \n",
    "2. Data Visualization • Machine Learning Algorithms • Data Wrangling \n",
    "\n",
    "Technical skills 2019\n",
    "1. Programming Tools: Python, R, VBA, SQL, SPSS \n",
    "(ii)  Data Visualization Tools: MS Excel, Tableau, Power BI \n",
    "3. Packages: Scikit-Learn, Numpy, Pandas, NLTK, BeautifulSoup, Matplotlib, Seaborn \n",
    "etc. \n",
    "4. Machine Learning: Clustering, Linear/Logistic Regression, SVM, PCA, Ensemble \n",
    "Trees, Random Forests \n",
    "\n",
    "Section 500.01 Definitions \n",
    "CBP -Controls MI & Insights at BARCLAYS ( Jan`23 - Present)\n",
    "Assistant Manager Analytics at PNB MetLife India Insurance Co. Ltd., Gurugram \n",
    "(Aug '21 – Jan`23)\n",
    "\n",
    "Internships\n",
    "(i) Data Analytics Intern at PNB MetLife India Insurance Co. Ltd., Gurugram (Mar \n",
    "'21 - Jul '21) \n",
    "(ii) Data Science Intern at Transabel Technology, Jaipur (Aug '20 - Nov \n",
    "'20)\n",
    "\n",
    "Certification 89\n",
    "1.  Certificate of competency in Fundamentals of Deep Learning for Computer Vision \n",
    "from NVIDIA Deep Learning Institute. \n",
    "2. Python for Data Science and Machine Learning Bootcamp from Udemy. \n",
    "3.  Associate Data Analytics from EXL.\n",
    "\"\"\"\n",
    "\n",
    "# Split the text into lines\n",
    "lines = pdf_text.strip().split('\\n')\n",
    "\n",
    "# Initialize variables to store titles and descriptions\n",
    "output = []\n",
    "title = None\n",
    "description = \"\"\n",
    "\n",
    "# Process each line to extract titles and descriptions\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        continue\n",
    "    \n",
    "    if title is None:\n",
    "        title = line\n",
    "    else:\n",
    "        description += line + \" \"\n",
    "        if line.endswith('.'):\n",
    "            output.append({'Title': title, 'Description': description})\n",
    "            title = None\n",
    "            description = \"\"\n",
    "\n",
    "# Create a DataFrame from the output\n",
    "df = pd.DataFrame(output)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d4162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "# Sample text from the PDF\n",
    "pdf_text = \"\"\"\n",
    "...  # Your PDF text here\n",
    "\"\"\"\n",
    "\n",
    "# Sample dataframe with names to match against\n",
    "data_to_match_df = pd.DataFrame({\n",
    "    'name': [\n",
    "        \"priyanhi-shukla-good girlnope joker\",\n",
    "        \"potato beans goodaamir is good\",\n",
    "        \"shubhandi-makes good food(C1-02-10)-nice gulab jal\",\n",
    "        \"my name khan(C2-10-67)- Shahrukh khan Kajol\",\n",
    "        \"kisi ka bhayi kisi ki jan(C2-10-67)- Soleman bhayi Kajol\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Split the text into lines\n",
    "lines = pdf_text.strip().split('\\n')\n",
    "\n",
    "# Initialize variables to store titles and descriptions\n",
    "title = \"\"\n",
    "description = \"\"\n",
    "output = []\n",
    "\n",
    "# Process each line to extract titles and descriptions\n",
    "for line in lines:\n",
    "    if re.match(r'^[A-Za-z\\s]+$', line):\n",
    "        # Save previous title and description if any\n",
    "        if title and description:\n",
    "            output.append({'Title': title, 'Description': description})\n",
    "        title = line.strip()\n",
    "        description = \"\"\n",
    "    else:\n",
    "        description += line + \"\\n\"\n",
    "\n",
    "# Save the last title and description\n",
    "if title and description:\n",
    "    output.append({'Title': title, 'Description': description})\n",
    "\n",
    "# Create a DataFrame from the output\n",
    "df = pd.DataFrame(output)\n",
    "\n",
    "# Sample function to calculate match scores, keywords, and store results\n",
    "def match_and_store(row):\n",
    "    match_scores = []\n",
    "    matched_keywords = []\n",
    "    for _, row_to_match in data_to_match_df.iterrows():\n",
    "        match_text = row_to_match['name']\n",
    "        match_score = fuzz.token_set_ratio(row['Title'] + \" \" + row['Description'], match_text)\n",
    "        match_scores.append(match_score)\n",
    "        matched_keywords.append(match_text)\n",
    "    max_match_score = max(match_scores)\n",
    "    best_matched_keyword = matched_keywords[match_scores.index(max_match_score)]\n",
    "    row['MatchScore'] = max_match_score\n",
    "    row['MatchedKeyword'] = best_matched_keyword\n",
    "    return row\n",
    "\n",
    "# Apply the function to each row\n",
    "result_df = df.apply(match_and_store, axis=1)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913077a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import process\n",
    "\n",
    "# Sample text from the PDF\n",
    "pdf_text = \"\"\"\n",
    "...  # Your PDF text here\n",
    "\"\"\"\n",
    "\n",
    "# Sample dataframe with names to match against\n",
    "data_to_match_df = pd.DataFrame({\n",
    "    'name': [\n",
    "        \"priyanhi-shukla-good girlnope joker\",\n",
    "        \"potato beans goodaamir is good\",\n",
    "        \"shubhandi-makes good food(C1-02-10)-nice gulab jal\",\n",
    "        \"my name khan(C2-10-67)- Shahrukh khan Kajol\",\n",
    "        \"kisi ka bhayi kisi ki jan(C2-10-67)- Soleman bhayi Kajol\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Split the text into lines\n",
    "lines = pdf_text.strip().split('\\n')\n",
    "\n",
    "# Initialize variables to store titles and descriptions\n",
    "title = \"\"\n",
    "description = \"\"\n",
    "output = []\n",
    "\n",
    "# Process each line to extract titles and descriptions\n",
    "for line in lines:\n",
    "    if re.match(r'^[A-Za-z\\s]+$', line):\n",
    "        # Save previous title and description if any\n",
    "        if title and description:\n",
    "            output.append({'Title': title, 'Description': description})\n",
    "        title = line.strip()\n",
    "        description = \"\"\n",
    "    else:\n",
    "        description += line + \"\\n\"\n",
    "\n",
    "# Save the last title and description\n",
    "if title and description:\n",
    "    output.append({'Title': title, 'Description': description})\n",
    "\n",
    "# Create a DataFrame from the output\n",
    "df = pd.DataFrame(output)\n",
    "\n",
    "# Sample function to calculate top 5 matches for each description\n",
    "def match_top_5(row):\n",
    "    matches = process.extract(row['Description'], data_to_match_df['name'], limit=5)\n",
    "    matched_names = [match[0] for match in matches]\n",
    "    match_scores = [match[1] for match in matches]\n",
    "    matched_keywords = ', '.join(matched_names)\n",
    "    row['MatchedNames'] = matched_keywords\n",
    "    row['MatchScores'] = ', '.join(map(str, match_scores))\n",
    "    return row\n",
    "\n",
    "# Apply the function to each row\n",
    "result_df = df.apply(match_top_5, axis=1)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e39747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import process\n",
    "\n",
    "# Sample text from the PDF\n",
    "pdf_text = \"\"\"\n",
    "...  # Your PDF text here\n",
    "\"\"\"\n",
    "\n",
    "# Sample dataframe with names to match against\n",
    "data_to_match_df = pd.DataFrame({\n",
    "    'name': [\n",
    "        \"priyanhi-shukla-good girlnope joker\",\n",
    "        \"potato beans goodaamir is good\",\n",
    "        \"shubhandi-makes good food(C1-02-10)-nice gulab jal\",\n",
    "        \"my name khan(C2-10-67)- Shahrukh khan Kajol\",\n",
    "        \"kisi ka bhayi kisi ki jan(C2-10-67)- Soleman bhayi Kajol\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Split the text into lines\n",
    "lines = pdf_text.strip().split('\\n')\n",
    "\n",
    "# Initialize variables to store titles and descriptions\n",
    "title = \"\"\n",
    "description = \"\"\n",
    "output = []\n",
    "\n",
    "# Process each line to extract titles and descriptions\n",
    "for line in lines:\n",
    "    if re.match(r'^[A-Za-z\\s]+$', line):\n",
    "        # Save previous title and description if any\n",
    "        if title and description:\n",
    "            output.append({'Title': title, 'Description': description})\n",
    "        title = line.strip()\n",
    "        description = \"\"\n",
    "    else:\n",
    "        description += line + \"\\n\"\n",
    "\n",
    "# Save the last title and description\n",
    "if title and description:\n",
    "    output.append({'Title': title, 'Description': description})\n",
    "\n",
    "# Create a DataFrame from the output\n",
    "df = pd.DataFrame(output)\n",
    "\n",
    "# Sample function to calculate top 5 matches for each description\n",
    "def match_top_5(row):\n",
    "    matches = process.extract(row['Description'], data_to_match_df['name'], limit=5)\n",
    "    matched_names = [match[0] for match in matches]\n",
    "    match_scores = [match[1] for match in matches]\n",
    "    matched_keywords = ', '.join(matched_names)\n",
    "    row['MatchedNames'] = matched_keywords\n",
    "    row['MatchScores'] = ', '.join(map(str, match_scores))\n",
    "    return row\n",
    "\n",
    "# Apply the function to each row\n",
    "result_df = df.apply(match_top_5, axis=1)\n",
    "\n",
    "# Merge with the original data_to_match_df to get matched names\n",
    "result_df = result_df.merge(data_to_match_df, left_on='MatchedNames', right_on='name', how='left')\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Sample extracted text\n",
    "extracted_text = \"\"\"\n",
    "A Data Science enthusiast who wants to take up a good professional challenge...\n",
    "\"\"\"\n",
    "\n",
    "# Create a PDF document object\n",
    "doc = fitz.open(\"input.pdf\")  # Replace with your PDF file\n",
    "\n",
    "# Initialize variables\n",
    "titles = []\n",
    "descriptions = []\n",
    "current_title = None\n",
    "\n",
    "# Iterate through each page in the PDF\n",
    "for page_num in range(doc.page_count):\n",
    "    page = doc.load_page(page_num)\n",
    "    text = page.get_text()\n",
    "    \n",
    "    # Process each line on the page\n",
    "    for line in text.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            # Check if the line is bold\n",
    "            if \"font\" in page.get_page_text_attributes(line)[\"font\"].lower():\n",
    "                if current_title is not None:\n",
    "                    titles.append(current_title)\n",
    "                current_title = line\n",
    "            else:\n",
    "                if current_title is not None:\n",
    "                    descriptions.append(line)\n",
    "    titles.append(current_title)\n",
    "\n",
    "# Close the PDF document\n",
    "doc.close()\n",
    "\n",
    "# Create a DataFrame from titles and descriptions\n",
    "data = {'Title': titles, 'Description': descriptions}\n",
    "result_df = pd.DataFrame(data)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
