{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0751f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Define a list of common stopwords to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        title = row['Title']\n",
    "        description = row['Description']\n",
    "        objective = row['Objective']\n",
    "        objective_name = row['Objective Name']  # Assuming this column exists in your Excel data\n",
    "        \n",
    "        matched_title_keywords = []\n",
    "        matched_description_keywords = []\n",
    "        matched_objective_keywords = []\n",
    "        \n",
    "        for keyword in title.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_sort_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords:\n",
    "                matched_title_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in description.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_sort_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords:\n",
    "                matched_description_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in objective_name.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_sort_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords:\n",
    "                matched_objective_keywords.append(best_match_info[0])\n",
    "        \n",
    "        description_score = round(fuzz.token_sort_ratio(description.lower(), paragraph_text.lower()))\n",
    "        objective_score = round(fuzz.token_sort_ratio(objective.lower(), paragraph_text.lower()))\n",
    "        \n",
    "        matching_entry = {\n",
    "            'All paragraph': paragraph_text,\n",
    "            'Title': title,\n",
    "            'Objective': objective,\n",
    "            'Description': description,\n",
    "            'Matched Description': ', '.join(matched_description_keywords),\n",
    "            'Description Match Score with paragraph': description_score,\n",
    "            'Objective Name': objective_name,\n",
    "            'Matched objective name': ', '.join(matched_objective_keywords),\n",
    "            'Objective Name Match Score with paragraph': objective_score,\n",
    "            'Page Number': paragraph_number\n",
    "        }\n",
    "        \n",
    "        # Only append the entry if there are matched keywords in Description or Objective Name\n",
    "        if matched_description_keywords or matched_objective_keywords:\n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058fd22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Define a list of common stopwords to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        title = row['Title']\n",
    "        description = row['Description']\n",
    "        objective = row['Objective']\n",
    "        objective_name = row['Objective Name']  # Assuming this column exists in your Excel data\n",
    "        \n",
    "        matched_title_keywords = []\n",
    "        matched_description_keywords = []\n",
    "        matched_objective_keywords = []\n",
    "        \n",
    "        for keyword in title.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_sort_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords:\n",
    "                matched_title_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in description.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_sort_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords:\n",
    "                matched_description_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in objective_name.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_sort_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords:\n",
    "                matched_objective_keywords.append(best_match_info[0])\n",
    "        \n",
    "        description_score = round(fuzz.token_sort_ratio(description.lower(), paragraph_text.lower()))\n",
    "        objective_score = round(fuzz.token_sort_ratio(objective.lower(), paragraph_text.lower()))\n",
    "        \n",
    "        matching_entry = {\n",
    "            'All paragraph': paragraph_text,\n",
    "            'Title': title,\n",
    "            'Objective': objective,\n",
    "            'Description': description,\n",
    "            'Matched Description': ', '.join(set(matched_description_keywords)),  # Use set to remove duplicates\n",
    "            'Description Match Score with paragraph': description_score,\n",
    "            'Objective Name': objective_name,\n",
    "            'Matched objective name': ', '.join(set(matched_objective_keywords)),  # Use set to remove duplicates\n",
    "            'Objective Name Match Score with paragraph': objective_score,\n",
    "            'Page Number': paragraph_number\n",
    "        }\n",
    "        \n",
    "        # Only append the entry if there are matched keywords in Description or Objective Name\n",
    "        if matched_description_keywords or matched_objective_keywords:\n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d4a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    return cleaned_keyword\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        title = row['Title']\n",
    "        description = row['Description']\n",
    "        objective = row['Objective']\n",
    "        objective_name = row['Objective Name']  # Assuming this column exists in your Excel data\n",
    "        \n",
    "        matched_title_keywords = []\n",
    "        matched_description_keywords = []\n",
    "        matched_objective_keywords = []\n",
    "        \n",
    "        for keyword in title.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_title_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in description.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_description_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in objective_name.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_objective_keywords.append(best_match_info[0])\n",
    "        \n",
    "        description_score = round(fuzz.token_set_ratio(description.lower(), paragraph_text.lower()))\n",
    "        objective_score = round(fuzz.token_set_ratio(objective.lower(), paragraph_text.lower()))\n",
    "        \n",
    "        matching_entry = {\n",
    "            'All paragraph': paragraph_text,\n",
    "            'Title': title,\n",
    "            'Objective': objective,\n",
    "            'Description': description,\n",
    "            'Matched Description': ', '.join(set(matched_description_keywords)),  # Use set to remove duplicates\n",
    "            'Description Match Score with paragraph': description_score,\n",
    "            'Objective Name': objective_name,\n",
    "            'Matched objective name': ', '.join(set(matched_objective_keywords)),  # Use set to remove duplicates\n",
    "            'Objective Name Match Score with paragraph': objective_score,\n",
    "            'Page Number': paragraph_number\n",
    "        }\n",
    "        \n",
    "        # Only append the entry if there are matched keywords in Description or Objective Name\n",
    "        if matched_description_keywords or matched_objective_keywords:\n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        title = row['Title']\n",
    "        description = row['Description']\n",
    "        objective = row['Objective']\n",
    "        objective_name = row['Objective Name']  # Assuming this column exists in your Excel data\n",
    "        \n",
    "        matched_title_keywords = []\n",
    "        matched_description_keywords = []\n",
    "        matched_objective_keywords = []\n",
    "        \n",
    "        for keyword in title.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_title_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in description.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_description_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in objective_name.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_objective_keywords.append(best_match_info[0])\n",
    "        \n",
    "        description_score = round(fuzz.token_set_ratio(description.lower(), paragraph_text.lower()))\n",
    "        objective_score = round(fuzz.token_set_ratio(objective.lower(), paragraph_text.lower()))\n",
    "        \n",
    "        matching_entry = {\n",
    "            'All paragraph': paragraph_text,\n",
    "            'Title': title,\n",
    "            'Objective': objective,\n",
    "            'Description': description,\n",
    "            'Matched Description': ', '.join(set(matched_description_keywords)),  # Use set to remove duplicates\n",
    "            'Description Match Score with paragraph': description_score,\n",
    "            'Objective Name': objective_name,\n",
    "            'Matched objective name': ', '.join(set(matched_objective_keywords)),  # Use set to remove duplicates\n",
    "            'Objective Name Match Score with paragraph': objective_score,\n",
    "            'Page Number': paragraph_number\n",
    "        }\n",
    "        \n",
    "        # Only append the entry if there are matched keywords in Description or Objective Name\n",
    "        if matched_description_keywords or matched_objective_keywords:\n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "#matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        title = row['Title']\n",
    "        description = row['Description']\n",
    "        objective = row['Objective']\n",
    "        objective_name = row['Objective Name']  # Assuming this column exists in your Excel data\n",
    "        \n",
    "        matched_title_keywords = []\n",
    "        matched_description_keywords = []\n",
    "        matched_objective_keywords = []\n",
    "        \n",
    "        for keyword in title.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_title_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in description.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_description_keywords.append(best_match_info[0])\n",
    "        \n",
    "        for keyword in objective_name.split('\\n'):\n",
    "            keyword = keyword.strip()\n",
    "            keyword = clean_keyword(keyword)\n",
    "            \n",
    "            best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_objective_keywords.append(best_match_info[0])\n",
    "        \n",
    "        description_score = round(fuzz.token_set_ratio(description.lower(), paragraph_text.lower()))\n",
    "        objective_score = round(fuzz.token_set_ratio(objective.lower(), paragraph_text.lower()))\n",
    "        title_score = round(fuzz.token_set_ratio(title.lower(), paragraph_text.lower()))\n",
    "        \n",
    "        matching_entry = {\n",
    "            'All paragraph': paragraph_text,\n",
    "            'Title': title,\n",
    "            'Objective': objective,\n",
    "            'Description': description,\n",
    "            'Matched Description': ', '.join(set(matched_description_keywords)),  # Use set to remove duplicates\n",
    "            'Description Match Score with Paragraph': description_score,\n",
    "            'Matched Title': ', '.join(set(matched_title_keywords)),  # Use set to remove duplicates\n",
    "            'Title Match Score with Paragraph': title_score,\n",
    "            'Objective Name': objective_name,\n",
    "            'Matched Objective Name': ', '.join(set(matched_objective_keywords)),  # Use set to remove duplicates\n",
    "            'Objective Name Match Score with Paragraph': objective_score,\n",
    "            'Page Number': paragraph_number\n",
    "        }\n",
    "        \n",
    "        # Only append the entry if there are matched keywords in Description, Title, or Objective Name\n",
    "        if matched_description_keywords or matched_title_keywords or matched_objective_keywords:\n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e46e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Choose the column to match (e.g., \"Description\")\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "        match_score = best_match_info[1]\n",
    "        \n",
    "        if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "            matched_keywords = best_match_info[0]\n",
    "            \n",
    "            # Store the matching details in the results\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Matched {column_to_match}': matched_keywords,\n",
    "                f'{column_to_match} Match Score with Paragraph': match_score,\n",
    "                'Page Number': paragraph_number\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40766196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Choose the column to match (e.g., \"Description\")\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        best_match_info = process.extractOne(keyword.lower(), paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "        match_score = best_match_info[1]\n",
    "        \n",
    "        if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "            matched_keywords = best_match_info[0]\n",
    "            \n",
    "            # Store the matching details in the results\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': matched_keywords,\n",
    "                f'{column_to_match} Match Score with Paragraph': match_score,\n",
    "                'Page Number': paragraph_number\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "#matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a7116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Choose the column to match (e.g., \"Description\")\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Split the keyword into individual words and match each word\n",
    "        for kw in keyword.lower().split():\n",
    "            best_match_info = process.extractOne(kw, paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_keywords.append((best_match_info[0], match_score))\n",
    "            \n",
    "        # Store the matching details in the results\n",
    "        if matched_keywords:\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "                f'{column_to_match} Match Scores with Paragraph': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "                'Page Number': paragraph_number\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# Choose the column to match (e.g., \"Description\")\n",
    "column_to_match = \"Description\"\n",
    "\n",
    "matching_results = []\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Split the keyword into individual words and match each word\n",
    "        for kw in keyword.lower().split():\n",
    "            best_match_info = process.extractOne(kw, paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_keywords.append((best_match_info[0], match_score))\n",
    "            \n",
    "        # Store the matching details in the results\n",
    "        if matched_keywords:\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "                f'{column_to_match} Match Scores with Paragraph': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "                'Page Number': paragraph_number,\n",
    "                'A': row['A']  # Assuming 'A' is a column in your Excel data\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab62fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Define a list of common stopwords and unwanted characters to exclude from matching\n",
    "stopwords = [\"in\", \"the\", \"what\", \"why\", \"at\", \"and\", \"to\", \"of\", \"a\", \"an\", \"is\"]  # Add more stopwords as needed\n",
    "unwanted_characters = r\"[,.;@#?!&$-]\"\n",
    "\n",
    "# ... (same code as before to extract PDF paragraphs and prepare Excel data) ...\n",
    "\n",
    "# Set the threshold for the match score\n",
    "threshold_score = 60\n",
    "\n",
    "# List of root words to exclude\n",
    "exclusion_roots = [\"technology\", \"secure\"]  # Add more root words as needed\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    # Remove unwanted characters and digits\n",
    "    cleaned_keyword = re.sub(unwanted_characters, '', keyword)\n",
    "    cleaned_keyword = ''.join(filter(lambda x: not x.isdigit(), cleaned_keyword))\n",
    "    \n",
    "    # Remove variations of exclusion root words\n",
    "    for root in exclusion_roots:\n",
    "        if root in cleaned_keyword:\n",
    "            cleaned_keyword = cleaned_keyword.replace(root, '')\n",
    "    \n",
    "    return cleaned_keyword.strip()\n",
    "\n",
    "for paragraph_number, paragraph_text in enumerate(pdf_paragraphs, start=1):\n",
    "    for index, row in excel_data.iterrows():\n",
    "        keyword = row[column_to_match]\n",
    "        keyword = keyword.strip()\n",
    "        keyword = clean_keyword(keyword)\n",
    "        \n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Split the keyword into individual words and match each word\n",
    "        for kw in keyword.lower().split():\n",
    "            best_match_info = process.extractOne(kw, paragraph_text.lower().split(), scorer=fuzz.token_set_ratio)\n",
    "            match_score = best_match_info[1]\n",
    "            \n",
    "            if match_score >= threshold_score and best_match_info[0] not in stopwords and len(best_match_info[0]) > 2:\n",
    "                matched_keywords.append((best_match_info[0], match_score))\n",
    "            \n",
    "        # Store the matching details in the results\n",
    "        if matched_keywords:\n",
    "            matching_entry = {\n",
    "                'All paragraph': paragraph_text,\n",
    "                f'Original {column_to_match}': keyword,\n",
    "                f'Matched {column_to_match}': ', '.join([kw[0] for kw in matched_keywords]),\n",
    "                f'{column_to_match} Match Scores with Paragraph': ', '.join([str(kw[1]) for kw in matched_keywords]),\n",
    "                'Page Number': paragraph_number,\n",
    "                'A': row['A']  # Assuming 'A' is a column in your Excel data\n",
    "            }\n",
    "            \n",
    "            matching_results.append(matching_entry)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "matching_df = pd.DataFrame(matching_results)\n",
    "\n",
    "# Save the matching results to a CSV file\n",
    "matching_df.to_csv('matching_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78114cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = {'your_column': ['COO-123- abc Something', 'COO-456def Another', 'COO-789ghi More']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove the pattern [SOME_TEXT]-[NUMERIC]-[ALPHABETIC] from the beginning of each value in the 'your_column'\n",
    "df['your_column'] = df['your_column'].str.replace(r'^[A-Z]+-\\d+-\\s*', '')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3192c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = {'your_column': ['COO-123- abc Something', 'COO-456def Another', 'COO-789ghi More']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove alphanumeric characters from the beginning of each value in the 'your_column'\n",
    "df['your_column'] = df['your_column'].str.replace(r'^[0-9a-zA-Z]+', '')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f682b4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c418355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953cd813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b13792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6713f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
